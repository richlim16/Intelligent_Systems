{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](./images/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3 # no of input channels (RGB)\n",
    "num_classes = 10 # classes for CIFAR 10 dataset\n",
    "\n",
    "device = 'cuda' # if running on desktop\n",
    "lr = 1e-2 #learning rates idk if this is constant\n",
    "epochs = 80\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 10 Dataset\n",
    "\n",
    "The CIFAR 10 dataset can be downloaded using pytorch. we may also utilize dataloader function of pytorch to process the data easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of commands for transforming the image\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert image to tensor\n",
    "    transforms.CenterCrop(28) # crop from the center\n",
    "])\n",
    "\n",
    "# create a function that normalizes each image\n",
    "def norm_image(data_sample):\n",
    "    img_tensor = data_sample[0] # get image values/tensors\n",
    "    label = data_sample[1]\n",
    "\n",
    "    img_means = img_tensor.mean(axis=[1,2]) # get the mean of the image per channel\n",
    "    img_sds = img_tensor.std(axis=[1,2]) # get over SD of the image per channel\n",
    "\n",
    "    mean_sub = img_tensor - img_means.unsqueeze(1).unsqueeze(2) # subtract the mean\n",
    "    img_norm = mean_sub.true_divide(img_sds.unsqueeze(1).unsqueeze(2)) # divide by SD\n",
    "\n",
    "    return (img_norm, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#training set\n",
    "all_train = list(datasets.CIFAR10(root = 'data/', transform = img_transform, train=True, download=True)) #unsure about download value\n",
    "\n",
    "random.shuffle(all_train)\n",
    "\n",
    "train_data = all_train[:40000]\n",
    "train_transformed = list(map(norm_image, train_data))\n",
    "train_loader = DataLoader(dataset=train_transformed, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# get a validation of 10k images\n",
    "val_data = all_train[40000:]\n",
    "val_tranformed = list(map(norm_image, val_data))\n",
    "val_loader = DataLoader(dataset=val_tranformed, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#test data\n",
    "#perform on the test data as well\n",
    "test_data = datasets.CIFAR10(root = 'data/', transform = img_transform, train=False, download=False ) #unsure about download value\n",
    "test_transformed = list(map(norm_image, test_data))\n",
    "test_loader = DataLoader(dataset=test_transformed, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a classes for modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for the convolution module\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.relu = nn.ReLU() #relu\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) # convolution\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels) # batch normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "#class for the inception block\n",
    "class inception_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_ch1, out_ch3):\n",
    "        super(inception_block, self).__init__()\n",
    "        #first conv module; padding should be 'same'\n",
    "        self.ch1 = conv_block(in_channels=in_channels, out_channels=out_ch1, kernel_size=(3,3), stride=(1,1), padding='same')\n",
    "        #second conv module; padding should be 'same' to be able to concatenate them together\n",
    "        self.ch3 = conv_block(in_channels=in_channels, out_channels=out_ch3, kernel_size=(3,3), stride=(1,1), padding='same') \n",
    "\n",
    "    def forward(self, x):\n",
    "        #concat the outputs of the convolutions / aka Merge\n",
    "        return torch.cat([self.ch1(x), self.ch3(x)], 1)\n",
    "    \n",
    "# createclass for the downsample module\n",
    "class downsample_block(nn.Module):\n",
    "    def __init__(self, in_channels, conv_out):\n",
    "        super(downsample_block, self).__init__()\n",
    "        #conv module\n",
    "        self.convblock = conv_block(in_channels, conv_out, kernel_size=(3,3), stride=(2,2))\n",
    "        # max pooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.convblock(x), self.maxpool(x)], 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting the model together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10, dropout_prob=0):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1 = conv_block(in_channels=3, out_channels=96, kernel_size=(3,3), stride=(1,1))\n",
    "\n",
    "        self.inception1 = inception_block(96, 32, 32) # first part comes from the output of the previous layer\n",
    "        self.inception2 = inception_block(64, 32, 48) # example 32 + 32 = 64\n",
    "        self.downsample1 = downsample_block(80, 80) # 32 + 48 = 80\n",
    "\n",
    "        self.inception3 = inception_block(160, 112, 48)\n",
    "        self.inception4 = inception_block(160, 96, 64)\n",
    "        self.inception5 = inception_block(160, 80, 80)\n",
    "        self.inception6 = inception_block(160, 48, 96)\n",
    "        self.downsample2 = downsample_block(114, 96)\n",
    "\n",
    "        self.inception7 = inception_block(240, 176, 160)\n",
    "        self.inception8 = inception_block(336, 176, 160)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(7, 7), padding=(1,1))\n",
    "        self.dropout = nn.Dropout(p = dropout_prob)\n",
    "        self.fc = nn.Linear(336, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.downsample1(x)\n",
    "\n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = self.downsample2(x)\n",
    "\n",
    "        x = self.inception7(x)\n",
    "        x = self.inception8(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Create the Model then set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# creating the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mInception\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#change val for dropout prob\u001b[39;00m\n\u001b[0;32m      4\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss() \u001b[38;5;66;03m# because of multi classification\u001b[39;00m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[1;32mc:\\Users\\Rich\\Documents\\School\\IS\\Intelligent_Systems\\is_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rich\\Documents\\School\\IS\\Intelligent_Systems\\is_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rich\\Documents\\School\\IS\\Intelligent_Systems\\is_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rich\\Documents\\School\\IS\\Intelligent_Systems\\is_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\Rich\\Documents\\School\\IS\\Intelligent_Systems\\is_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rich\\Documents\\School\\IS\\Intelligent_Systems\\is_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "model = Inception(in_channels=3, num_classes=10, dropout_prob=0).to(device) #change val for dropout prob\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() # because of multi classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.LinearLR(optimizer) # scheduler controls the flow of information in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reate 2 functions that obtain the metric on the train set and the test set\n",
    "\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train() # start the training process\n",
    "    curr_loss_train = 0 # initialize values\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for ind, (data_train, true_labels_train) in enumerate(train_loader):\n",
    "        data_train = data_train.to(device=device)\n",
    "        true_labels_train = true_labels_train.to(device=device)\n",
    "\n",
    "        out_train = model(data_train) # apply model to train data\n",
    "        loss_train = loss_function(out_train, true_labels_train) # get loss\n",
    "\n",
    "        optimizer.zer_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss_train += loss_train.item()\n",
    "        ix, predicted_train = out_train.max(1)\n",
    "        correct_train += predicted_train.eq(true_labels_train).sum().item()\n",
    "        total_train += true_labels_train.size(0)\n",
    "\n",
    "        train_loss = curr_loss_train/len(train_loader) # get the loss\n",
    "        acc_train_val = (correct_train/total_train)*100 # get the accuracy\n",
    "\n",
    "        train_acc.append(acc_train_val)\n",
    "        train_all_loss.append(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval() # start the testing process / eval mode\n",
    "    curr_loss_test = 0 # initialize values\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    num_class=10\n",
    "    confusion_matrix = torch.zeros(num_class, num_class) # get the confusion matrix of the test set\n",
    "    with torch.no_grad():\n",
    "        for data_test, true_labels_test in test_loader:\n",
    "\n",
    "            data_test = data_test.to(device=device)\n",
    "            true_labels_test = true_labels_test.to(device=device)\n",
    "\n",
    "            out_test = model(data_test) # apply model to train data\n",
    "            loss_test = loss_function(out_test, true_labels_test) # get loss\n",
    "\n",
    "            curr_loss_test += loss_test.item()\n",
    "            ix, predicted_test = out_test.max(1)\n",
    "            correct_test += predicted_test.eq(true_labels_test).sum().item()\n",
    "            total_test += true_labels_test.size(0)\n",
    "\n",
    "            for tr, pr in zip(true_labels_test.view(-1), predicted_test.view(-1)):\n",
    "                confusion_matrix[tr.long(), pr.long()] += 1\n",
    "\n",
    "    test_loss = curr_loss_test/len(test_loader) # get the loss\n",
    "    acc_test_val = (correct_test/total_test)*100 # get the accuracy\n",
    "\n",
    "    test_acc.append(acc_test_val)\n",
    "    test_all_loss.append(test_loss)\n",
    "    con_mats.append(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the metrics\n",
    "Train the model, get the metrics on the training set, then apply it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "train_all_loss = []\n",
    "\n",
    "test_acc = []\n",
    "test_all_loss = {}\n",
    "\n",
    "con_mats = []\n",
    "\n",
    "times = []\n",
    "\n",
    "train_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    ep_start = time.time()\n",
    "    print(epoch)\n",
    "    train(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_time = time.time() - ep_start\n",
    "    print(epoch_time)\n",
    "    times.append(epoch_time)\n",
    "\n",
    "train_time = time.time() - train_start\n",
    "print(f'run time: {train_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
