{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](./images/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3 # no of input channels (RGB)\n",
    "num_classes = 10 # classes for CIFAR 10 dataset\n",
    "\n",
    "device = 'cuda' # if running on desktop\n",
    "lr = 1e-2 #learning rates idk if this is constant\n",
    "epochs = 80\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR 10 Dataset\n",
    "\n",
    "The CIFAR 10 dataset can be downloaded using pytorch. we may also utilize dataloader function of pytorch to process the data easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of commands for transforming the image\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert image to tensor\n",
    "    transforms.CenterCrop(28) # crop from the center\n",
    "])\n",
    "\n",
    "# create a function that normalizes each image\n",
    "def norm_image(data_sample):\n",
    "    img_tensor = data_sample[0] # get image values/tensors\n",
    "    label = data_sample[1]\n",
    "\n",
    "    img_means = img_tensor.mean(axis=[1,2]) # get the mean of the image per channel\n",
    "    img_sds = img_tensor.std(axis=[1,2]) # get over SD of the image per channel\n",
    "\n",
    "    mean_sub = img_tensor - img_means.unsqueeze(1).unsqueeze(2) # subtract the mean\n",
    "    img_norm = mean_sub.true_divide(img_sds.unsqueeze(1).unsqueeze(2)) # divide by SD\n",
    "\n",
    "    return (img_norm, label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#training set\n",
    "all_train = list(datasets.CIFAR10(root = 'data/', transform = img_transform, train=True, download=True)) #unsure about download value\n",
    "\n",
    "random.shuffle(all_train)\n",
    "\n",
    "train_data = all_train[:40000]\n",
    "train_transformed = list(map(norm_image, train_data))\n",
    "train_loader = DataLoader(dataset=train_transformed, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# get a validation of 10k images\n",
    "val_data = all_train[40000:]\n",
    "val_tranformed = list(map(norm_image, val_data))\n",
    "val_loader = DataLoader(dataset=val_tranformed, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#test data\n",
    "#perform on the test data as well\n",
    "test_data = datasets.CIFAR10(root = 'data/', transform = img_transform, train=False, download=False ) #unsure about download value\n",
    "test_transformed = list(map(norm_image, test_data))\n",
    "test_loader = DataLoader(dataset=test_transformed, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a classes for modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for the convolution module\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.relu = nn.ReLU() #relu\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) # convolution\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels) # batch normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "#class for the inception block\n",
    "class inception_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_ch1, out_ch3):\n",
    "        super(inception_block, self).__init__()\n",
    "        #first conv module; padding should be 'same'\n",
    "        self.ch1 = conv_block(in_channels=in_channels, out_channels=out_ch1, kernel_size=(3,3), stride=(1,1), padding='same')\n",
    "        #second conv module; padding should be 'same' to be able to concatenate them together\n",
    "        self.ch3 = conv_block(in_channels=in_channels, out_channels=out_ch3, kernel_size=(3,3), stride=(1,1), padding='same') \n",
    "\n",
    "    def forward(self, x):\n",
    "        #concat the outputs of the convolutions / aka Merge\n",
    "        return torch.cat([self.ch1(x), self.ch3(x)], 1)\n",
    "    \n",
    "# createclass for the downsample module\n",
    "class downsample_block(nn.Module):\n",
    "    def __init__(self, in_channels, conv_out):\n",
    "        super(downsample_block, self).__init__()\n",
    "        #conv module\n",
    "        self.convblock = conv_block(in_channels, conv_out, kernel_size=(3,3), stride=(2,2))\n",
    "        # max pooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.convblock(x), self.maxpool(x)], 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting the model together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10, dropout_prob=0):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1 = conv_block(in_channels=3, out_channels=96, kernel_size=(3,3), stride=(1,1))\n",
    "\n",
    "        self.inception1 = inception_block(96, 32, 32) # first part comes from the output of the previous layer\n",
    "        self.inception2 = inception_block(64, 32, 48) # example 32 + 32 = 64\n",
    "        self.downsample1 = downsample_block(80, 80) # 32 + 48 = 80\n",
    "\n",
    "        self.inception3 = inception_block(160, 112, 48)\n",
    "        self.inception4 = inception_block(160, 96, 64)\n",
    "        self.inception5 = inception_block(160, 80, 80)\n",
    "        self.inception6 = inception_block(160, 48, 96)\n",
    "        self.downsample2 = downsample_block(144, 96)\n",
    "\n",
    "        self.inception7 = inception_block(240, 176, 160)\n",
    "        self.inception8 = inception_block(336, 176, 160)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(7, 7), padding=(1,1))\n",
    "        self.dropout = nn.Dropout(p = dropout_prob)\n",
    "        self.fc = nn.Linear(336, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.downsample1(x)\n",
    "\n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = self.downsample2(x)\n",
    "\n",
    "        x = self.inception7(x)\n",
    "        x = self.inception8(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Create the Model then set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "model = Inception(in_channels=3, num_classes=10, dropout_prob=0).to(device) #change val for dropout prob\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() # because of multi classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.LinearLR(optimizer) # scheduler controls the flow of information in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reate 2 functions that obtain the metric on the train set and the test set\n",
    "\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train() # start the training process\n",
    "    curr_loss_train = 0 # initialize values\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for ind, (data_train, true_labels_train) in enumerate(train_loader):\n",
    "        data_train = data_train.to(device=device)\n",
    "        true_labels_train = true_labels_train.to(device=device)\n",
    "\n",
    "        out_train = model(data_train) # apply model to train data\n",
    "        loss_train = loss_function(out_train, true_labels_train) # get loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss_train += loss_train.item()\n",
    "        ix, predicted_train = out_train.max(1)\n",
    "        correct_train += predicted_train.eq(true_labels_train).sum().item()\n",
    "        total_train += true_labels_train.size(0)\n",
    "\n",
    "        train_loss = curr_loss_train/len(train_loader) # get the loss\n",
    "        acc_train_val = (correct_train/total_train)*100 # get the accuracy\n",
    "\n",
    "        train_acc.append(acc_train_val)\n",
    "        train_all_loss.append(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval() # start the testing process / eval mode\n",
    "    curr_loss_test = 0 # initialize values\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    num_class=10\n",
    "    confusion_matrix = torch.zeros(num_class, num_class) # get the confusion matrix of the test set\n",
    "    with torch.no_grad():\n",
    "        for data_test, true_labels_test in test_loader:\n",
    "\n",
    "            data_test = data_test.to(device=device)\n",
    "            true_labels_test = true_labels_test.to(device=device)\n",
    "\n",
    "            out_test = model(data_test) # apply model to train data\n",
    "            loss_test = loss_function(out_test, true_labels_test) # get loss\n",
    "\n",
    "            curr_loss_test += loss_test.item()\n",
    "            ix, predicted_test = out_test.max(1)\n",
    "            correct_test += predicted_test.eq(true_labels_test).sum().item()\n",
    "            total_test += true_labels_test.size(0)\n",
    "\n",
    "            for tr, pr in zip(true_labels_test.view(-1), predicted_test.view(-1)):\n",
    "                confusion_matrix[tr.long(), pr.long()] += 1\n",
    "\n",
    "    test_loss = curr_loss_test/len(test_loader) # get the loss\n",
    "    acc_test_val = (correct_test/total_test)*100 # get the accuracy\n",
    "\n",
    "    test_acc.append(acc_test_val)\n",
    "    test_all_loss.append(test_loss)\n",
    "    con_mats.append(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the metrics\n",
    "Train the model, get the metrics on the training set, then apply it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.85688996315002\n",
      "1\n",
      "66.90397953987122\n",
      "2\n",
      "67.62147188186646\n",
      "3\n",
      "57.48777151107788\n",
      "4\n",
      "50.67724561691284\n",
      "5\n",
      "50.53305006027222\n",
      "6\n",
      "50.54710078239441\n",
      "7\n",
      "50.53807759284973\n",
      "8\n",
      "50.98540139198303\n",
      "9\n",
      "50.43864941596985\n",
      "10\n",
      "57.34963035583496\n",
      "11\n",
      "56.60908770561218\n",
      "12\n",
      "56.4509642124176\n",
      "13\n",
      "55.37633275985718\n",
      "14\n",
      "54.58513021469116\n",
      "15\n",
      "55.07923102378845\n",
      "16\n",
      "54.75496315956116\n",
      "17\n",
      "54.69509696960449\n",
      "18\n",
      "50.96074032783508\n",
      "19\n",
      "47.00078821182251\n",
      "20\n",
      "50.56401062011719\n",
      "21\n",
      "55.27487063407898\n",
      "22\n",
      "50.7008752822876\n",
      "23\n",
      "48.70212483406067\n",
      "24\n",
      "47.55451488494873\n",
      "25\n",
      "46.94573092460632\n",
      "26\n",
      "57.45134139060974\n",
      "27\n",
      "55.84408736228943\n",
      "28\n",
      "56.11075448989868\n",
      "29\n",
      "56.02310013771057\n",
      "30\n",
      "55.97839093208313\n",
      "31\n",
      "51.235411405563354\n",
      "32\n",
      "47.077486515045166\n",
      "33\n",
      "49.437774658203125\n",
      "34\n",
      "54.41886234283447\n",
      "35\n",
      "50.527411460876465\n",
      "36\n",
      "50.23560094833374\n",
      "37\n",
      "50.760645389556885\n",
      "38\n",
      "50.67552590370178\n",
      "39\n",
      "50.99362850189209\n",
      "40\n",
      "49.907371044158936\n",
      "41\n",
      "47.43209195137024\n",
      "42\n",
      "47.37214660644531\n",
      "43\n",
      "47.837684631347656\n",
      "44\n",
      "47.250335454940796\n",
      "45\n",
      "47.403449296951294\n",
      "46\n",
      "47.36969566345215\n",
      "47\n",
      "47.27232646942139\n",
      "48\n",
      "48.55863928794861\n",
      "49\n",
      "51.2245078086853\n",
      "50\n",
      "49.944538831710815\n",
      "51\n",
      "50.01747179031372\n",
      "52\n",
      "50.625349283218384\n",
      "53\n",
      "51.031630516052246\n",
      "54\n",
      "49.91389489173889\n",
      "55\n",
      "47.11271619796753\n",
      "56\n",
      "47.251540422439575\n",
      "57\n",
      "46.9390811920166\n",
      "58\n",
      "47.46744680404663\n",
      "59\n",
      "46.96351170539856\n",
      "60\n",
      "47.297550439834595\n",
      "61\n",
      "47.152207136154175\n",
      "62\n",
      "47.837422370910645\n",
      "63\n",
      "47.28227114677429\n",
      "64\n",
      "46.90278601646423\n",
      "65\n",
      "47.04004168510437\n",
      "66\n",
      "47.201120376586914\n",
      "67\n",
      "46.91303086280823\n",
      "68\n",
      "47.90624928474426\n",
      "69\n",
      "47.16180729866028\n",
      "70\n",
      "47.2619411945343\n",
      "71\n",
      "47.27807593345642\n",
      "72\n",
      "47.3483362197876\n",
      "73\n",
      "47.55503487586975\n",
      "74\n",
      "47.254775285720825\n",
      "75\n",
      "47.44708752632141\n",
      "76\n",
      "47.444095849990845\n",
      "77\n",
      "47.2331223487854\n",
      "78\n",
      "47.31181836128235\n",
      "79\n",
      "47.54560399055481\n",
      "run time: 4058.2555418014526\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "train_all_loss = []\n",
    "\n",
    "test_acc = []\n",
    "test_all_loss = {}\n",
    "\n",
    "con_mats = []\n",
    "\n",
    "times = []\n",
    "\n",
    "train_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    ep_start = time.time()\n",
    "    print(epoch)\n",
    "    train(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_time = time.time() - ep_start\n",
    "    print(epoch_time)\n",
    "    times.append(epoch_time)\n",
    "\n",
    "train_time = time.time() - train_start\n",
    "print(f'run time: {train_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
