{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# randomness\n",
    "seed = 42\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data downloaded from - https://www.kaggle.com/competitions/data-science-bowl-2018/data \n",
    "#importing datasets\n",
    "\n",
    "TRAIN_PATH = 'stage1_train/'\n",
    "TEST_PATH = 'stage1_test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the images present in the subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my version of getting images from subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ids = []\n",
    "# test_ids = []\n",
    "\n",
    "# for image_filename in os.listdir(TEST_PATH):\n",
    "#     test_ids.append(image_filename)\n",
    "\n",
    "    \n",
    "# for image_filename in os.listdir(TRAIN_PATH):\n",
    "#     train_ids.append(image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of my version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (128,128) into shape (128,128,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\richl\\Documents\\School\\4th Year\\2nd semester\\IS\\Homework\\Intelligent_Systems\\UNET\\Data\\UNET.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m img \u001b[39m=\u001b[39m imread(path) \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m img \u001b[39m=\u001b[39m resize(img, (IMG_HEIGHT, IMG_WIDTH), mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, preserve_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train[n] \u001b[39m=\u001b[39m img  \u001b[39m#Fill empty X_train with values from img\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((IMG_HEIGHT, IMG_WIDTH, \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m mask_file \u001b[39min\u001b[39;00m \u001b[39mnext\u001b[39m(os\u001b[39m.\u001b[39mwalk(path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/masks/\u001b[39m\u001b[39m'\u001b[39m))[\u001b[39m2\u001b[39m]:\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (128,128) into shape (128,128,3)"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = TRAIN_PATH+ '/' + id_\n",
    "    img = imread(path) \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img  #Fill empty X_train with values from img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)  \n",
    "            \n",
    "    Y_train[n] = mask   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Resizing test images') \n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu',\n",
    " kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
    " kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', \n",
    "kernel_initializer='he_normal', padding='same')(c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansion Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion Paths\n",
    "\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', \n",
    "padding='same')(c9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs + Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 128, 128, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)         448       ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128, 128, 16)         0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 16)         2320      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 16)           0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 32)           4640      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64, 64, 32)           0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 32)           9248      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 32)           0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)           18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 32, 32, 64)           0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 64)           36928     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 64)           0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 16, 16, 128)          0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 128)          147584    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 128)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 256)            295168    ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 8, 8, 256)            0         ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 256)            590080    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 16, 16, 128)          131200    ['conv2d_9[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 16, 256)          0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 128)          295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 16, 16, 128)          0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 128)          147584    ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)           32832     ['conv2d_11[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 32, 32, 128)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 64)           73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 32, 32, 64)           0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 64, 64, 32)           8224      ['conv2d_13[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 64, 64)           0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 32)           18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 64, 64, 32)           0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 32)           9248      ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 128, 128, 16)         2064      ['conv2d_15[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 128, 128, 32)         0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 16)         4624      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 128, 128, 16)         0         ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 128, 128, 16)         2320      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 128, 128, 1)          17        ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1941105 (7.40 MB)\n",
      "Trainable params: 1941105 (7.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.1`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\richl\\Documents\\School\\4th Year\\2nd semester\\IS\\Homework\\Intelligent_Systems\\UNET\\Data\\UNET.ipynb Cell 24\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m checkpointer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mmodel_for_nuclei.h5\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/richl/Documents/School/4th%20Year/2nd%20semester/IS/Homework/Intelligent_Systems/UNET/Data/UNET.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32md:\\richl\\Documents\\School\\4th Year\\2nd semester\\IS\\Homework\\Intelligent_Systems\\hw_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\richl\\Documents\\School\\4th Year\\2nd semester\\IS\\Homework\\Intelligent_Systems\\hw_env\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1785\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1782\u001b[0m split_at \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(math\u001b[39m.\u001b[39mfloor(batch_dim \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m validation_split)))\n\u001b[0;32m   1784\u001b[0m \u001b[39mif\u001b[39;00m split_at \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m split_at \u001b[39m==\u001b[39m batch_dim:\n\u001b[1;32m-> 1785\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1786\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTraining data contains \u001b[39m\u001b[39m{batch_dim}\u001b[39;00m\u001b[39m samples, which is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1787\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msufficient to split it into a validation and training set as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1788\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecified by `validation_split=\u001b[39m\u001b[39m{validation_split}\u001b[39;00m\u001b[39m`. Either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1789\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprovide more data, or a different value for the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1790\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`validation_split` argument.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1791\u001b[0m             batch_dim\u001b[39m=\u001b[39mbatch_dim, validation_split\u001b[39m=\u001b[39mvalidation_split\n\u001b[0;32m   1792\u001b[0m         )\n\u001b[0;32m   1793\u001b[0m     )\n\u001b[0;32m   1795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split\u001b[39m(t, start, end):\n\u001b[0;32m   1796\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.1`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', \n",
    "verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25, \n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(X_train))\n",
    "\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    " \n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()\n",
    "\n",
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
